{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDL Assignment #4: PID Control and Fruit Ninja\n",
    "*By Marcus Schwarting*\n",
    "\n",
    "This assignment covers proportional-integral-derivative (PID) control in a simple example of a heating process, then considers particle filters as a means of identifying target objects and navigating towards them. In order to run this code, there are two packages that you may need to install:\n",
    "\n",
    "- cv2 for creating images (`pip install opencv-python`)\n",
    "- ffmpeg for creating videos (`sudo apt install ffmpeg`)\n",
    "\n",
    "The rubric is broken down as follows:\n",
    "\n",
    "\n",
    "#### PID Control (25 points)\n",
    "- Implement PID control in the `Heating_Process.pid_controller` function (10 points).\n",
    "- Using the function calls below (including changes in setpoint and several kicks), identify values of $K_p, K_i, K_d \\neq 0$ that provide ideal control. See `pid_example.png` for an example of what a suitable level of control looks like. Hint: differences are often an order of magnitude, so $K_p \\approx 10 K_i \\approx 100 K_d$ (5 points).\n",
    "- Once suitable conditions are identified for the PID controller, increase and decrease the values of $K_p,K_i,K_d$ until abberant behavior occurs. For all eight cases, describe what went wrong and why (10 points).\n",
    "\n",
    "#### Fruit Ninja (75 points)\n",
    "- Implement a particle filter for a single fruit (select the watermelon). Using the `fruit_ninja.save_video` function create image frames and save a video where the crosshairs remain in place (no control), but particles and dead reckoning are shown. This should be coded in `CrosshairsController.particle_filter` (20 points).\n",
    "- Demonstrate the particle filter operating across all fruits. These should be three distinct particle filters performing localization separately (5 points).\n",
    "- Experiment with different values of $\\sigma$ (particle drift per frame), and number of particles, and justify why you selected the value of $\\sigma$ and number of particles for later tests (10 points).\n",
    "- Implement a controller in the `CrosshairsController.control()` function, which takes the crosshairs coordinates as well as the input image, uses the particle filter to assess the location of the fruit in the frame, and makes a decision about where to move the crosshairs, expressed as updated coordinates, passed to `FruitNinja.play_game()`. Justify your controller design decisions, such as how a fruit was selected, how the path of the fruit was anticipated, etc. Note: it is perfectly acceptable to have some fruit that you cannot catch (25 points).\n",
    "- With the completed particle filter and crosshairs controller, create a Fruit Ninja video (or several) showcasing the performance of your code. Demonstrate that your controller scores better than a controller that does not move (see `stagnant_crosshairs.mp4` for an example) (10 points).\n",
    "- Adjust the settings associated with the crosshairs speed (`max_controller_move` flag under `FruitNinja.play_game()`), and show that a faster crosshairs speed allows for a higher score while a slower crosshairs speed reduces scoring potential (5 points).\n",
    "\n",
    "#### Additional Notes\n",
    "- You are strongly encouraged to work in teams for this project.\n",
    "- If you run into errors or bugs in this code, reach out to the TA (Marcus Schwarting) via Slack at your earliest convenience.\n",
    "- You are welcome to make edits to any pre-written code that is part of the assignment (eg. `fruit_ninja.py`), but when you do so, please make a comment detailing what you changed and why.\n",
    "- When you are ready to submit your assignment, please zip the folder you are working in (including all videos, written report, etc.) and submit the `.zip` file to Canvas. For any portions requiring a write-up, please create a `README.md` to include all these items. Furthermore, for extra files you created, please leave some indication in the `README.md` as to what these files are and do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "from fruit_ninja import *\n",
    "\n",
    "# Ignore RankWarning\n",
    "warnings.filterwarnings(\"ignore\", category=np.RankWarning)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fruit Ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:44<00:00,  6.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.0 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.3.9.4)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.0_1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "Input #0, image2, from 'testing/*.png':\n",
      "  Duration: 00:00:10.00, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: png, rgba(pc, gbr/unknown/unknown), 640x480 [SAR 3937:3937 DAR 4:3], 30 fps, 30 tbr, 30 tbn\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x141020930] using SAR=1/1\n",
      "[libx264 @ 0x141020930] using cpu capabilities: ARMv8 NEON\n",
      "[libx264 @ 0x141020930] profile High, level 3.0, 4:2:0, 8-bit\n",
      "[libx264 @ 0x141020930] 264 - core 164 r3108 31e19f9 - H.264/MPEG-4 AVC codec - Copyleft 2003-2023 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=15 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'out.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf61.1.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 640x480 [SAR 1:1 DAR 4:3], q=2-31, 30 fps, 15360 tbn\n",
      "      Metadata:\n",
      "        encoder         : Lavc61.3.100 libx264\n",
      "      Side data:\n",
      "        cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "[out#0/mp4 @ 0x14101f810] video:1599KiB audio:0KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.271138%\n",
      "frame=  300 fps=0.0 q=-1.0 Lsize=    1603KiB time=00:00:09.93 bitrate=1322.1kbits/s speed=27.8x    \n",
      "[libx264 @ 0x141020930] frame I:2     Avg QP:20.23  size: 31391\n",
      "[libx264 @ 0x141020930] frame P:79    Avg QP:22.54  size:  6771\n",
      "[libx264 @ 0x141020930] frame B:219   Avg QP:27.63  size:  4743\n",
      "[libx264 @ 0x141020930] consecutive B-frames:  1.0%  2.7%  7.0% 89.3%\n",
      "[libx264 @ 0x141020930] mb I  I16..4: 30.8% 40.8% 28.4%\n",
      "[libx264 @ 0x141020930] mb P  I16..4:  0.1%  2.4%  1.4%  P16..4: 16.6%  3.5%  4.4%  0.0%  0.0%    skip:71.6%\n",
      "[libx264 @ 0x141020930] mb B  I16..4:  0.1%  0.4%  0.3%  B16..8: 14.5%  2.4%  1.6%  direct: 3.5%  skip:77.1%  L0:48.8% L1:46.4% BI: 4.8%\n",
      "[libx264 @ 0x141020930] 8x8 transform intra:51.3% inter:16.5%\n",
      "[libx264 @ 0x141020930] coded y,uvDC,uvAC intra: 75.5% 77.4% 75.9% inter: 8.4% 18.3% 17.9%\n",
      "[libx264 @ 0x141020930] i16 v,h,dc,p: 78% 10%  9%  3%\n",
      "[libx264 @ 0x141020930] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 38%  7% 18%  5%  7%  7%  5%  7%  6%\n",
      "[libx264 @ 0x141020930] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 32% 11% 17%  7%  8%  7%  5%  8%  5%\n",
      "[libx264 @ 0x141020930] i8c dc,h,v,p: 62% 10% 12% 16%\n",
      "[libx264 @ 0x141020930] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x141020930] ref P L0: 48.5%  6.8% 22.5% 22.2%\n",
      "[libx264 @ 0x141020930] ref B L0: 66.9% 27.2%  5.9%\n",
      "[libx264 @ 0x141020930] ref B L1: 83.8% 16.2%\n",
      "[libx264 @ 0x141020930] kb/s:1309.19\n"
     ]
    }
   ],
   "source": [
    "class CrosshairsController:\n",
    "    def __init__(self, total_particles=200):\n",
    "        self.total_particles = total_particles\n",
    "        self.W_particles = []\n",
    "        self.S_particles = []\n",
    "        self.O_particles = []\n",
    "        self.W_particle_weights = []\n",
    "        self.S_particle_weights = []\n",
    "        self.O_particle_weights = []\n",
    "\n",
    "        # background color distribution\n",
    "        self.background = None\n",
    "        # which if any fruit is being hunted atm\n",
    "        self.curr_Hunt = None\n",
    "\n",
    "        # for each fruit maintain\n",
    "        # color distribution, shape, if its found at the moment\n",
    "        # a list of average points from each step, and last average point to see if filter is stuck\n",
    "        self.w_color_gen = None\n",
    "        self.wShape = (154, 157)\n",
    "        self.wFound = False\n",
    "        self.wBestP = []\n",
    "        self.wLastP = None\n",
    "\n",
    "        self.s_color_gen = None\n",
    "        self.sShape = (158, 150)\n",
    "        self.sFound = False\n",
    "        self.sBestP = []\n",
    "        self.sLastP = None\n",
    "\n",
    "        self.o_color_gen = None\n",
    "        self.oShape = (190, 152)\n",
    "        self.oFound = False\n",
    "        self.oBestP = []\n",
    "        self.oLastP = None\n",
    "\n",
    "    # INITALIZING FUNCTIONS\n",
    "\n",
    "    # scan background and check for overlapping pixels\n",
    "    def scan_background(self):\n",
    "\n",
    "        img_size = np.array([512, 1024, 3])\n",
    "        image = cv2.resize(\n",
    "            cv2.cvtColor(\n",
    "                cv2.imread(\n",
    "                    \"/Users/bayardwalsh/Desktop/Assignment4BayardIreneKevin/SDL_Fruit_Ninja/fruit_imgs/wood_background.png\"\n",
    "                ),\n",
    "                cv2.COLOR_BGR2RGB,\n",
    "            ),\n",
    "            (img_size[1], img_size[0]),\n",
    "        )\n",
    "\n",
    "        c_dst = np.zeros((256, 256, 256))\n",
    "        height, width, _ = image.shape\n",
    "        pixel_counts = {}\n",
    "        for y in range(height):\n",
    "            for x in range(width):\n",
    "                pixel_value = tuple(image[y, x])\n",
    "                pixel_counts[pixel_value] = pixel_counts.get(pixel_value, 0) + 1\n",
    "\n",
    "        for pixel_value, count in pixel_counts.items():\n",
    "            c_dst[pixel_value] = count\n",
    "\n",
    "        # account for crosshairs location by adding high count crosshair colors (and tracking dots)\n",
    "        c_dst[(255, 255, 255)] = 100\n",
    "        c_dst[(255, 255, 0)] = 100\n",
    "        c_dst[(255, 0, 255)] = 100\n",
    "        c_dst[(0, 255, 255)] = 100\n",
    "        c_dst[(255, 0, 0)] = 100\n",
    "        c_dst[(0, 255, 0)] = 100\n",
    "        c_dst[(0, 0, 255)] = 100\n",
    "        c_dst[(0, 0, 0)] = 100\n",
    "\n",
    "        self.background = c_dst\n",
    "\n",
    "    # get distrubutions based on likliehood of being a given image for every pixel\n",
    "    # this is loaded once initially for each fruit and assumes background is run\n",
    "    # averages pixels in background and fruit to prevent false positives\n",
    "    # highly weights pixels in fruit and NOT in background\n",
    "    def particle_weights(self, image, fruit):\n",
    "        height, width, _ = image.shape\n",
    "        c_dst = np.zeros((256, 256, 256))\n",
    "\n",
    "        pixel_counts = {}\n",
    "\n",
    "        for y in range(height):\n",
    "            for x in range(width):\n",
    "                pixel_value = tuple(image[y, x])\n",
    "\n",
    "                pixel_counts[pixel_value] = pixel_counts.get(pixel_value, 0) + 1\n",
    "\n",
    "        for pixel_value, count in pixel_counts.items():\n",
    "            r, g, b, = (\n",
    "                int(pixel_value[0] * 255),\n",
    "                int(pixel_value[1] * 255),\n",
    "                int(pixel_value[2] * 255),\n",
    "            )\n",
    "            if self.background[r, g, b] == 0:\n",
    "                c_dst[r, g, b] = 1\n",
    "            else:\n",
    "                c_dst[r, g, b] = (count) / (count + self.background[r, g, b])\n",
    "\n",
    "        match fruit:\n",
    "            case \"watermelon\":\n",
    "                self.w_color_gen = c_dst\n",
    "            case \"strawberry\":\n",
    "                self.s_color_gen = c_dst\n",
    "            case \"orange\":\n",
    "                self.o_color_gen = c_dst\n",
    "            case _:\n",
    "                raise\n",
    "\n",
    "    # GENERATE PIXEL FUNCTIONS\n",
    "\n",
    "    # random point search\n",
    "    def get_random_points(self, img, num_points=1000):\n",
    "        height, width, _ = img.shape\n",
    "        random_x = np.random.randint(0, width, num_points)\n",
    "        random_y = np.random.randint(0, height, num_points)\n",
    "        random_points = np.column_stack((random_x, random_y))\n",
    "\n",
    "        return random_points\n",
    "\n",
    "    # weight point distribution\n",
    "    def get_weights_from_points(self, img, points, fruit):\n",
    "        match fruit:\n",
    "            case \"w\":\n",
    "                ref = self.w_color_gen\n",
    "            case \"s\":\n",
    "                ref = self.s_color_gen\n",
    "            case \"o\":\n",
    "                ref = self.o_color_gen\n",
    "            case _:\n",
    "                raise ValueError(\"Invalid fruit type\")\n",
    "\n",
    "        weights = []\n",
    "        for (x, y) in points:\n",
    "            r, g, b = img[y, x]\n",
    "            weights.append(ref[r, g, b])\n",
    "\n",
    "        return weights\n",
    "\n",
    "    # given a fruit and points, resample random points with sigma distribution and relative to fruit shape.\n",
    "    def resample(self, img, points, fruit, sigma=5, num_points=500):\n",
    "        new_points = []\n",
    "        height, width, _ = img.shape\n",
    "        attr_shape = f\"{fruit}Shape\"\n",
    "        shape_height, shape_width = getattr(self, attr_shape)\n",
    "        weights = self.get_weights_from_points(img, points, fruit)\n",
    "\n",
    "        # no points found, fruit is lost, reset to random search\n",
    "        if np.sum(weights) == 0:\n",
    "            setattr(self, f\"{fruit}Found\", False)\n",
    "            return self.get_random_points(img)\n",
    "\n",
    "        weights /= np.sum(weights)\n",
    "\n",
    "        for _ in range(num_points):\n",
    "            while True:\n",
    "                chosen_index = np.random.choice(len(points), p=weights)\n",
    "                chosen_point = points[chosen_index]\n",
    "                random_offsets_x = np.random.randint(\n",
    "                    -shape_height / 4 * 1 / sigma, shape_height / 4 * 1 / sigma\n",
    "                )\n",
    "                random_offsets_y = np.random.randint(\n",
    "                    -shape_width / 4 * 1 / sigma, shape_width / 4 * 1 / sigma\n",
    "                )\n",
    "                new_point = chosen_point + np.array(\n",
    "                    [random_offsets_x, random_offsets_y]\n",
    "                )\n",
    "                if (0 <= new_point[0] < width) and (0 <= new_point[1] < height):\n",
    "                    new_points.append(new_point.astype(int))\n",
    "                    break\n",
    "\n",
    "        return np.array(new_points)\n",
    "\n",
    "    # MOVEMENT FUNCTIONSs\n",
    "\n",
    "    # calculate dead reckoning from polynomial fnc to get next best point\n",
    "    def get_dead_reckoning(self, points):\n",
    "        x = np.array([point[0] for point in points])\n",
    "        y = np.array([point[1] for point in points])\n",
    "\n",
    "        try:\n",
    "            coefficients = np.polyfit(x, y, 2)\n",
    "        except np.linalg.LinAlgError:\n",
    "            # Handle the exception, fallback to a linear fit or other method\n",
    "            print(\"Warning: SVD did not converge, using linear fit as fallback.\")\n",
    "            coefficients = np.polyfit(x, y, 1)\n",
    "            a, b = coefficients\n",
    "            c = 0  # For a linear fit, c will be zero\n",
    "\n",
    "        if len(coefficients) == 2:\n",
    "            a, b = coefficients\n",
    "            c = 0\n",
    "        else:\n",
    "            a, b, c = coefficients\n",
    "\n",
    "        next_x = x[-1] + (x[-1] - x[-2]) if len(x) > 1 else x[-1] + 1\n",
    "        next_y = a * next_x**2 + b * next_x + c\n",
    "\n",
    "        return round(next_x), round(next_y)\n",
    "\n",
    "    # based on the current fruit hunting, move cursor towards fruit based on dead reckoning\n",
    "    def calculate_next_cursor_position(\n",
    "        self, cursor_pos, object_pos, cursor_speed, time_step=1\n",
    "    ):\n",
    "        cursor_pos = np.array(cursor_pos)\n",
    "        object_pos = np.array(object_pos)\n",
    "        direction_vector = object_pos - cursor_pos\n",
    "        distance_to_object = np.linalg.norm(direction_vector)\n",
    "        if distance_to_object <= cursor_speed * time_step:\n",
    "            return tuple(object_pos)\n",
    "        direction_vector_normalized = direction_vector / distance_to_object\n",
    "        new_cursor_pos = (\n",
    "            cursor_pos + direction_vector_normalized * cursor_speed * time_step\n",
    "        )\n",
    "\n",
    "        return tuple(new_cursor_pos)\n",
    "\n",
    "    # calls particle filter for given fruit\n",
    "    def particle_filter(\n",
    "        self,\n",
    "        curr_image,\n",
    "        curr_particles,\n",
    "        curr_particle_weights,\n",
    "        fruit,\n",
    "        sigma=1.5,\n",
    "    ):\n",
    "        hitpoints = []\n",
    "\n",
    "        f = getattr(self, f\"{fruit}Found\")\n",
    "\n",
    "        # if fruit not found generate random search points\n",
    "        if not f:\n",
    "            setattr(\n",
    "                self, f\"{fruit.upper()}_particles\", self.get_random_points(curr_image)\n",
    "            )\n",
    "        # if found resample points with sigma distribution and color weighting\n",
    "        else:\n",
    "            bestpart = getattr(self, f\"{fruit.upper()}_particles\")\n",
    "            self.get_weights_from_points(curr_image, bestpart, fruit)\n",
    "            setattr(\n",
    "                self,\n",
    "                f\"{fruit.upper()}_particles\",\n",
    "                self.resample(curr_image, bestpart, fruit, sigma=sigma),\n",
    "            )\n",
    "\n",
    "        for (x, y) in curr_particles:\n",
    "            attr = f\"{fruit}_color_gen\"\n",
    "            r, g, b = curr_image[y, x]\n",
    "            dist = getattr(self, attr)[r, g, b]\n",
    "            if (\n",
    "                dist == 1\n",
    "            ):  # only take average of \"good points\" (in fruit and not in background)\n",
    "                hitpoints.append((x, y))\n",
    "\n",
    "        if len(hitpoints) != 0:\n",
    "            match fruit:\n",
    "                case \"w\":\n",
    "                    self.wFound = True\n",
    "                    self.wBestP.append(np.round(np.mean(hitpoints, axis=0)).astype(int))\n",
    "                case \"o\":\n",
    "                    self.oFound = True\n",
    "                    self.oBestP.append(np.round(np.mean(hitpoints, axis=0)).astype(int))\n",
    "                case \"s\":\n",
    "                    self.sFound = True\n",
    "                    self.sBestP.append(np.round(np.mean(hitpoints, axis=0)).astype(int))\n",
    "\n",
    "    def control(self, crosshairs_pos, curr_image, killedfruits, max_dist=20, show=True, move_cursor=True):\n",
    "\n",
    "        # reset filters on 3 instances\n",
    "        # 1) fruit is killed\n",
    "        # 2) fruit is missed/ offscreen\n",
    "        # 3) fruit is \"stuck\" on background ie not moving\n",
    "        def reset_fruit_status(fruit, bestP_attr, found_attr, lastP_attr):\n",
    "            if fruit in killedfruits:\n",
    "                setattr(self, found_attr, False)\n",
    "                setattr(self, bestP_attr, [])\n",
    "                setattr(self, lastP_attr, None)\n",
    "            bestP = getattr(self, bestP_attr)\n",
    "            lastP = getattr(self, lastP_attr)\n",
    "            if bestP:\n",
    "                if bestP[-1][1] + 5 > 512:\n",
    "                    setattr(self, found_attr, False)\n",
    "                    setattr(self, bestP_attr, [])\n",
    "                    setattr(self, lastP_attr, None)\n",
    "                elif lastP is None:\n",
    "                    setattr(self, lastP_attr, bestP[-1])\n",
    "                elif np.array_equal(bestP[-1], lastP):\n",
    "                    setattr(self, found_attr, False)\n",
    "                    setattr(self, bestP_attr, [])\n",
    "                    setattr(self, lastP_attr, None)\n",
    "                else:\n",
    "                    setattr(self, lastP_attr, bestP[-1])\n",
    "\n",
    "        fruits = [\n",
    "            (\"w\", \"wBestP\", \"wFound\", \"wLastP\"),\n",
    "            (\"o\", \"oBestP\", \"oFound\", \"oLastP\"),\n",
    "            (\"s\", \"sBestP\", \"sFound\", \"sLastP\"),\n",
    "        ]\n",
    "\n",
    "        for fruit, bestP_attr, found_attr, lastP_attr in fruits:\n",
    "            reset_fruit_status(fruit, bestP_attr, found_attr, lastP_attr)\n",
    "\n",
    "        # Call particle filters for each fruit\n",
    "        self.particle_filter(curr_image, self.W_particles, self.W_particle_weights, \"w\")\n",
    "\n",
    "        self.particle_filter(curr_image, self.O_particles, self.O_particle_weights, \"o\")\n",
    "\n",
    "        self.particle_filter(curr_image, self.S_particles, self.S_particle_weights, \"s\")\n",
    "\n",
    "        #  move cursor or not\n",
    "        if move_cursor:\n",
    "            points = []\n",
    "            coords = {\n",
    "                \"w\": (self.wFound, self.wBestP),\n",
    "                \"o\": (self.oFound, self.oBestP),\n",
    "                \"s\": (self.sFound, self.sBestP),\n",
    "            }\n",
    "            positions = {\"w\": None, \"o\": None, \"s\": None}\n",
    "\n",
    "            for key, (found, bestP) in coords.items():\n",
    "                if found:\n",
    "                    positions[key] = self.get_dead_reckoning(bestP)\n",
    "                    points.append(positions[key])\n",
    "\n",
    "            if points:\n",
    "                xP, yP = crosshairs_pos\n",
    "                cp = np.array(crosshairs_pos)\n",
    "\n",
    "                if self.curr_Hunt and not coords[self.curr_Hunt][0]:\n",
    "                    self.curr_Hunt = None\n",
    "\n",
    "                if self.curr_Hunt is None:\n",
    "                    distances = {\n",
    "                        key: np.linalg.norm(pos - cp)\n",
    "                        for key, pos in positions.items()\n",
    "                        if pos is not None\n",
    "                    }\n",
    "                    if distances:\n",
    "                        self.curr_Hunt = min(distances, key=distances.get)\n",
    "\n",
    "                if self.curr_Hunt:\n",
    "                    p = positions[self.curr_Hunt]\n",
    "                    crosshairs_pos = self.calculate_next_cursor_position(\n",
    "                        (xP, yP), p, max_dist\n",
    "                    )\n",
    "\n",
    "        # draw particles or not\n",
    "        if show:\n",
    "            particle_groups = [\n",
    "                (self.W_particles, self.wBestP, (0, 0, 255)),\n",
    "                (self.O_particles, self.oBestP, (0, 255, 0)),\n",
    "                (self.S_particles, self.sBestP, (255, 0, 0)),\n",
    "            ]\n",
    "\n",
    "            for particles, bestP, color in particle_groups:\n",
    "                for (x, y) in particles:\n",
    "                    cv2.circle(curr_image, (x, y), 2, color, -1)\n",
    "\n",
    "                if len(bestP) != 0:\n",
    "                    (xx, yy) = self.get_dead_reckoning(bestP)\n",
    "                    cv2.circle(curr_image, (xx, yy), 15, color, -1)\n",
    "\n",
    "                if len(bestP) > 1:\n",
    "                    for i in range(1, len(bestP)):\n",
    "                        p1 = bestP[i - 1]\n",
    "                        p2 = bestP[i]\n",
    "                        cv2.line(curr_image, p1, p2, color, thickness=2)\n",
    "\n",
    "        return crosshairs_pos\n",
    "\n",
    "\n",
    "# Example usage\n",
    "\n",
    "# NOTE: reset the file paths for each fruit and scan background\n",
    "controller = CrosshairsController()\n",
    "controller.scan_background()\n",
    "imagew = mpimg.imread(\n",
    "    \"/Users/bayardwalsh/Desktop/Assignment4BayardIreneKevin/SDL_Fruit_Ninja/fruit_imgs/watermelon.png\"\n",
    ")\n",
    "imageo = mpimg.imread(\n",
    "    \"/Users/bayardwalsh/Desktop/Assignment4BayardIreneKevin/SDL_Fruit_Ninja/fruit_imgs/orange.png\"\n",
    ")\n",
    "images = mpimg.imread(\n",
    "    \"/Users/bayardwalsh/Desktop/Assignment4BayardIreneKevin/SDL_Fruit_Ninja/fruit_imgs/strawberry.png\"\n",
    ")\n",
    "\n",
    "controller.particle_weights(imagew, \"watermelon\")\n",
    "controller.particle_weights(imageo, \"orange\")\n",
    "controller.particle_weights(images, \"strawberry\")\n",
    "\n",
    "FNinja = FruitNinja()\n",
    "FNinja.play_game(controller.control, game_length=300, save_vid_folder=\"testing\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eimspred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
